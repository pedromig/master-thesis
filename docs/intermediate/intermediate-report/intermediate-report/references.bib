@article{alarie2021two,
  title = {Two Decades of Blackbox Optimization Applications},
  author = {Alarie, Stéphane and Audet, Charles and Gheribi, Aïmen E. and Kokkolaras, Michael and Le Digabel, Sébastien},
  date = {2021-01-01},
  journaltitle = {EURO Journal on Computational Optimization},
  shortjournal = {EURO Journal on Computational Optimization},
  volume = {9},
  pages = {100011},
  issn = {2192-4406},
  doi = {10.1016/j.ejco.2021.100011},
  url = {https://www.sciencedirect.com/science/article/pii/S2192440621001386},
  urldate = {2023-01-10},
  abstract = {This article reviews blackbox optimization applications of direct search optimization methods over the past twenty years. Emphasis is placed on the Mesh Adaptive Direct Search (Mads) derivative-free optimization algorithm. The main focus is on applications in three specific fields: energy, materials science, and computational engineering design. Nevertheless, other applications in science and engineering, including patents, are also considered. The breadth of applications demonstrates the versatility of Mads and highlights the evolution of its accompanying software NOMAD as a standard tool for blackbox optimization.},
  langid = {english},
  keywords = {Applications,Blackbox optimization,Derivative-free optimization,Mesh adaptive direct search},
  file = {/home/pedro/Documents/doc/zotero/Alarie et al_2021_Two decades of blackbox optimization applications.pdf;/home/pedro/Zotero/storage/XG2UYSI9/S2192440621001386.html}
}

@article{blummetaheuristics,
  title = {Metaheuristics in Combinatorial Optimization},
  author = {Blum, Christian},
  journaltitle = {ACM Computing Surveys},
  volume = {35},
  number = {3},
  langid = {english},
  file = {/home/pedro/Zotero/storage/FVMR32EN/Blum - Metaheuristics in combinatorial optimization.pdf}
}

@incollection{doerr2020complexity,
  title = {Complexity {{Theory}} for {{Discrete Black-Box Optimization Heuristics}}},
  booktitle = {Theory of {{Evolutionary Computation}}: {{Recent Developments}} in {{Discrete Optimization}}},
  author = {Doerr, Carola},
  editor = {Doerr, Benjamin and Neumann, Frank},
  date = {2020},
  series = {Natural {{Computing Series}}},
  pages = {133--212},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-29414-4_3},
  url = {https://doi.org/10.1007/978-3-030-29414-4_3},
  urldate = {2023-01-10},
  abstract = {A predominant topic in the theory of evolutionary algorithms and, more generally, theory of randomized black-box optimization techniques is running-time analysis. Running-time analysis is aimed at understanding the performance of a given heuristic on a given problem by bounding the number of function evaluations that are needed by the heuristic to identify a solution of a desired quality. As in general algorithms theory, this running-time perspective is most useful when it is complemented by a meaningful complexity theory that studies the limits of algorithmic solutions.},
  isbn = {978-3-030-29414-4},
  langid = {english},
  file = {/home/pedro/Documents/doc/zotero/Doerr_2020_Complexity Theory for Discrete Black-Box Optimization Heuristics.pdf}
}

@incollection{dorigo2010anta,
  title = {Ant {{Colony Optimization}}: {{Overview}} and {{Recent Advances}}},
  shorttitle = {Ant {{Colony Optimization}}},
  booktitle = {Handbook of {{Metaheuristics}}},
  author = {Dorigo, Marco and Stützle, Thomas},
  editor = {Gendreau, Michel and Potvin, Jean-Yves},
  date = {2010},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  pages = {227--263},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4419-1665-5_8},
  url = {https://doi.org/10.1007/978-1-4419-1665-5_8},
  urldate = {2023-01-15},
  abstract = {Ant Colony Optimization (ACO) is a metaheuristic that is inspired by the pheromone trail laying and following behavior of some ant species. Artificial ants in ACO are stochastic solution construction procedures that build candidate solutions for the problem instance under concern by exploiting (artificial) pheromone information that is adapted based on the ants’ search experience and possibly available heuristic information. Since the proposal of the Ant System, the first ACO algorithm, many significant research results have been obtained. These contributions focused on the development of high-performing algorithmic variants, the development of a generic algorithmic framework for ACO algorithms, successful applications of ACO algorithms to a wide range of computationally hard problems, and the theoretical understanding of properties of ACO algorithms. This chapter reviews these developments and gives an overview of recent research trends in ACO.},
  isbn = {978-1-4419-1665-5},
  langid = {english},
  keywords = {Heuristic Information,Local Search Algorithm,Pheromone Trail,Solution Component,Travel Salesman Problem},
  file = {/home/pedro/Documents/doc/zotero/Dorigo_Stützle_2010_Ant Colony Optimization.pdf}
}

@inproceedings{festa2014brief,
  title = {A Brief Introduction to Exact, Approximation, and Heuristic Algorithms for Solving Hard Combinatorial Optimization Problems},
  booktitle = {2014 16th {{International Conference}} on {{Transparent Optical Networks}} ({{ICTON}})},
  author = {Festa, P.},
  date = {2014-07},
  pages = {1--20},
  issn = {2161-2064},
  doi = {10.1109/ICTON.2014.6876285},
  abstract = {This paper presents a short (and not exhaustive) introduction to the most used exact, approximation, and metaheuristic algorithms for solving hard combinatorial optimization problems. After introducing the basics of exact approaches such as Branch \& Bound and Dynamic Programming, we focus on the basics of the most studied approximation techniques and of the most applied algorithms for finding good suboptimal solutions, including genetic algorithms, simulated annealing, tabu search, variable neighborhood search, greedy randomized adaptive search procedures (GRASP), path relinking, and scatter search.},
  eventtitle = {2014 16th {{International Conference}} on {{Transparent Optical Networks}} ({{ICTON}})},
  keywords = {Approximate solutions,Approximation algorithms,Approximation methods,Dynamic programming,Exact solution,Hard combinatorial optimization,Heuristic algorithms,Linear programming,Metaheuristics,Optimized production technology},
  file = {/home/pedro/Documents/doc/zotero/Festa_2014_A brief introduction to exact, approximation, and heuristic algorithms for.pdf;/home/pedro/Zotero/storage/8XJGU9EV/6876285.html}
}

@online{fonseca2021nasf4nio,
  title = {Nasf4nio},
  author = {Fonseca, Carlos M.},
  date = {2021-10-27T15:22:26Z},
  origdate = {2018-10-26T12:34:34Z},
  url = {https://github.com/cmfonseca/nasf4nio},
  urldate = {2023-01-15},
  abstract = {Not Another Software Framework for Nature-Inspired Optimization}
}

@incollection{gendreau2010tabua,
  title = {Tabu {{Search}}},
  booktitle = {Handbook of {{Metaheuristics}}},
  author = {Gendreau, Michel and Potvin, Jean-Yves},
  editor = {Gendreau, Michel and Potvin, Jean-Yves},
  date = {2010},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  pages = {41--59},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4419-1665-5_2},
  url = {https://doi.org/10.1007/978-1-4419-1665-5_2},
  urldate = {2023-01-15},
  abstract = {This chapter presents the fundamental concepts of tabu search (TS) in a tutorial fashion. Special emphasis is put on showing the relationships with classical local search methods and on the basic elements of any TS heuristic, namely the definition of the search space, the neighborhood structure, and the search memory. Other sections cover other important concepts such as search intensification and diversification and provide references to significant work on TS. Recent advances in TS are also briefly discussed.},
  isbn = {978-1-4419-1665-5},
  langid = {english},
  keywords = {Neighborhood Structure,Search Space,Tabu List,Tabu Search,Tabu Search Heuristic},
  file = {/home/pedro/Documents/doc/zotero/Gendreau_Potvin_2010_Tabu Search.pdf}
}

@book{glover1999tabu,
  title = {Tabu Search {{I}}},
  author = {Glover, Fred and Laguna, Manuel},
  date = {1999-01-01},
  journaltitle = {ORSA Journal on Computing},
  volume = {1},
  doi = {10.1287/ijoc.1.3.190},
  abstract = {This paper presents the fundamental principles underlying tabu search as a strategy for combinatorial optimization problems. Tabu search has achieved impressive practical successes in applications ranging from scheduling and computer channel balancing to cluster analysis and space planning, and more recently has demonstrated its value in treating classical problems such as the traveling salesman and graph coloring problems. Nevertheless, the approach is still in its infancy, and a good deal remains to be discovered about its most effective forms of implementation and about the range of problems for which it is best suited. This paper undertakes to present the major ideas and findings to date, and to indicate challenges for future research. Part I of this study indicates the basic principles, ranging from the short-term memory process at the core of the search to the intermediate and long term memory processes for intensifying and diversifying the search. Included are illustrative data structures for implementing the tabu conditions (and associated aspiration criteria) that underlie these processes. Part I concludes with a discussion of probabilistic tabu search and a summary of computational experience for a variety of applications. Part II of this study (to appear in a subsequent issue) examines more advanced considerations, applying the basic ideas to special settings and outlining a dynamic move structure to insure finiteness. Part II also describes tabu search methods for solving mixed integer programming problems and gives a brief summary of additional practical experience, including the use of tabu search to guide other types of processes, such as those of neural networks. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.},
  isbn = {978-0-7923-9965-0},
  file = {/home/pedro/Documents/doc/zotero/Glover_Laguna_1999_Tabu search I.pdf}
}

@online{google2014hash,
  title = {Hash {{Code}} - {{Google}}’s {{Coding Competitions}}},
  shorttitle = {Hash {{Code Problem Archive}}},
  author = {Google, HashCode},
  date = {2014},
  url = {https://codingcompetitions.withgoogle.com/hashcode/archive},
  urldate = {2023-01-10},
  abstract = {A team programming competition — you pick your team and coding language to solve an engineering problem. Are you up for the challenge?},
  langid = {english},
  organization = {{Coding Competitions}},
  file = {/home/pedro/Zotero/storage/FYZJWTTN/archive.html}
}

@incollection{hiriart-urruty1995conditions,
  title = {Conditions for {{Global Optimality}}},
  booktitle = {Handbook of {{Global Optimization}}},
  author = {Hiriart-Urruty, J.-B.},
  editor = {Horst, Reiner and Pardalos, Panos M.},
  date = {1995},
  series = {Nonconvex {{Optimization}} and {{Its Applications}}},
  pages = {1--26},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4615-2025-2_1},
  url = {https://doi.org/10.1007/978-1-4615-2025-2_1},
  urldate = {2023-01-10},
  abstract = {Given an optimization problem we are interested in getting characterizations of its global solutions, i.e., necessary and sufficient conditions for a feasible point to be a global minimum (or maximum) of the objective function. We review here recent theoretical results in that direction, emphasizing those which have led to algorithms for global optimization.},
  isbn = {978-1-4615-2025-2},
  langid = {english},
  keywords = {Convex Function,Global Minimum,Global Optimality,Quadratic Form,Trust Region},
  file = {/home/pedro/Zotero/storage/9ARF3SBU/Hiriart-Urruty - 1995 - Conditions for Global Optimality.pdf}
}

@article{johnson1974approximation,
  title = {Approximation Algorithms for Combinatorial Problems},
  author = {Johnson, David S.},
  date = {1974-12-01},
  journaltitle = {Journal of Computer and System Sciences},
  shortjournal = {Journal of Computer and System Sciences},
  volume = {9},
  number = {3},
  pages = {256--278},
  issn = {0022-0000},
  doi = {10.1016/S0022-0000(74)80044-9},
  url = {https://www.sciencedirect.com/science/article/pii/S0022000074800449},
  urldate = {2023-01-13},
  abstract = {Simple, polynomial-time, heuristic algorithms for finding approximate solutions to various polynomial complete optimization problems are analyzed with respect to their worst case behavior, measured by the ratio of the worst solution value that can be chosen by the algorithm to the optimal value. For certain problems, such as a simple form of the kanpsack problem and an optimization problem based on satisfiability testing, there are algorithms for which this ratio is bounded by a constant, independent of the problem size. For a number of set covering problems, simple algorithms yield worst case ratios which can grow with the log of the problem size. And for the problem of finding the maximum clique in a graph, no algorithm has been found for which the ratio does not grow at least as fast as nε, where n is the problem size and ε{$>$}0 depends on the algorithm.},
  langid = {english},
  file = {/home/pedro/Documents/doc/zotero/Johnson_1974_Approximation algorithms for combinatorial problems.pdf;/home/pedro/Zotero/storage/Z2683GCR/S0022000074800449.html}
}

@article{kirkpatrick1983optimization,
  title = {Optimization by {{Simulated Annealing}}},
  author = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
  date = {1983-05-13},
  journaltitle = {Science},
  volume = {220},
  number = {4598},
  pages = {671--680},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.220.4598.671},
  url = {https://www.science.org/doi/abs/10.1126/science.220.4598.671},
  urldate = {2023-01-15},
  abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
  file = {/home/pedro/Documents/doc/zotero/Kirkpatrick et al_1983_Optimization by Simulated Annealing.pdf}
}

@incollection{lourenco2010iterateda,
  title = {Iterated {{Local Search}}: {{Framework}} and {{Applications}}},
  shorttitle = {Iterated {{Local Search}}},
  booktitle = {Handbook of {{Metaheuristics}}},
  author = {Lourenço, Helena R. and Martin, Olivier C. and Stützle, Thomas},
  editor = {Gendreau, Michel and Potvin, Jean-Yves},
  date = {2010},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  pages = {363--397},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4419-1665-5_12},
  url = {https://doi.org/10.1007/978-1-4419-1665-5_12},
  urldate = {2023-01-15},
  abstract = {The key idea underlying iterated local search is to focus the search not on the full space of all candidate solutions but on the solutions that are returned by some underlying algorithm, typically a local search heuristic. The resulting search behavior can be characterized as iteratively building a chain of solutions of this embedded algorithm. The result is also a conceptually simple metaheuristic that nevertheless has led to state-of-the-art algorithms for many computationally hard problems. In fact, very good performance is often already obtained by rather straightforward implementations of the metaheuristic. In addition, the modular architecture of iterated local search makes it very suitable for an algorithm engineering approach where, progressively, the algorithms’ performance can be further optimized. Our purpose here is to give an accessible description of the underlying principles of iterated local search and a discussion of the main aspects that need to be taken into account for a successful application of it. In addition, we review the most important applications of this method and discuss its relationship to other metaheuristics.},
  isbn = {978-1-4419-1665-5},
  langid = {english},
  keywords = {Acceptance Criterion,Local Search,Local Search Algorithm,Travel Salesman Problem,Variable Neighborhood Search},
  file = {/home/pedro/Documents/doc/zotero/Lourenço et al_2010_Iterated Local Search2.pdf}
}

@book{luke2013essentialsa,
  title = {Essentials of {{Metaheuristics}}},
  author = {Luke, Sean},
  date = {2013},
  edition = {Second Edition},
  url = {https://cs.gmu.edu/~sean/book/metaheuristics/},
  urldate = {2023-01-11},
  file = {/home/pedro/Documents/doc/zotero/Luke_2013_Essentials of Metaheuristics.pdf;/home/pedro/Zotero/storage/Z8GUI84X/metaheuristics.html}
}

@article{martello1981bound,
  title = {A {{Bound}} and {{Bound}} Algorithm for the Zero-One Multiple Knapsack Problem},
  author = {Martello, Silvano and Toth, Paolo},
  date = {1981-11-01},
  journaltitle = {Discrete Applied Mathematics},
  shortjournal = {Discrete Applied Mathematics},
  series = {Special {{Copy}}},
  volume = {3},
  number = {4},
  pages = {275--288},
  issn = {0166-218X},
  doi = {10.1016/0166-218X(81)90005-6},
  url = {https://www.sciencedirect.com/science/article/pii/0166218X81900056},
  urldate = {2023-01-16},
  abstract = {By the term “Bound and Bound” we define a particular tree-search technique for the ILP, which, for a maximization problem, makes use of a lower bound to determine the branches to follow in the decision tree. This technique is applied to the solution of the Zero-One Multiple Knapsack Problem and an algorithm is derived; an illustrative example of the procedure is provided. We present extensive computational results showing that the method is capable of solving problems up to 4 knapsacks and 200 variables with running times considerably smaller than those of the most commonly utilized algorithms.},
  langid = {english},
  file = {/home/pedro/Documents/doc/zotero/Martello_Toth_1981_A Bound and Bound algorithm for the zero-one multiple knapsack problem.pdf;/home/pedro/Zotero/storage/WH7KBDLN/0166218X81900056.html}
}

@article{marti2013multistart,
  title = {Multi-Start Methods for Combinatorial Optimization},
  author = {Martí, Rafael and Resende, Mauricio G. C. and Ribeiro, Celso C.},
  date = {2013-04-01},
  journaltitle = {European Journal of Operational Research},
  shortjournal = {European Journal of Operational Research},
  volume = {226},
  number = {1},
  pages = {2},
  issn = {0377-2217},
  doi = {10.1016/j.ejor.2012.10.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0377221712007394},
  urldate = {2023-01-10},
  abstract = {Multi-start methods strategically sample the solution space of an optimization problem. The most successful of these methods have two phases that are alternated for a certain number of global iterations. The first phase generates a solution and the second seeks to improve the outcome. Each global iteration produces a solution that is typically a local optimum, and the best overall solution is the output of the algorithm. The interaction between the two phases creates a balance between search diversification (structural variation) and search intensification (improvement), to yield an effective means for generating high-quality solutions. This survey briefly sketches historical developments that have motivated the field, and then focuses on modern contributions that define the current state-of-the-art. We consider two categories of multi-start methods: memory-based and memoryless procedures. The former are based on identifying and recording specific types of information (attributes) to exploit in future constructions. The latter are based on order statistics of sampling and generate unconnected solutions. An interplay between the features of these two categories provides an inviting area for future exploration.},
  langid = {english},
  keywords = {Adaptive memory programming,GRASP,Metaheuristics,Multi-start methods},
  file = {/home/pedro/Documents/doc/zotero/Martí et al_2013_Multi-start methods for combinatorial optimization.pdf;/home/pedro/Zotero/storage/LRZN7P6K/S0377221712007394.html}
}

@incollection{nikolaev2010simulateda,
  title = {Simulated {{Annealing}}},
  booktitle = {Handbook of {{Metaheuristics}}},
  author = {Nikolaev, Alexander G. and Jacobson, Sheldon H.},
  editor = {Gendreau, Michel and Potvin, Jean-Yves},
  date = {2010},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  pages = {1--39},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4419-1665-5_1},
  url = {https://doi.org/10.1007/978-1-4419-1665-5_1},
  urldate = {2023-01-15},
  abstract = {Simulated annealing is a well-studied local search metaheuristic used to address discrete and, to a lesser extent, continuous optimization problems. The key feature of simulated annealing is that it provides a mechanism to escape local optima by allowing hill-climbing moves (i.e., moves which worsen the objective function value) in hopes of finding a global optimum. A brief history of simulated annealing is presented, including a review of its application to discrete, continuous, and multi-objective optimization problems. Asymptotic convergence and finite-time performance theory for simulated annealing are reviewed. Other local search algorithms are discussed in terms of their relationship to simulated annealing. The chapter also presents practical guidelines for the implementation of simulated annealing in terms of cooling schedules, neighborhood functions, and appropriate applications.},
  isbn = {978-1-4419-1665-5},
  langid = {english},
  keywords = {Discrete Optimization Problem,Simulated Annealing,Simulated Annealing Algorithm,Tabu Search,Travel Salesman Problem},
  file = {/home/pedro/Documents/doc/zotero/Nikolaev_Jacobson_2010_Simulated Annealing.pdf}
}

@book{nocedal2006numerical,
  title = {Numerical {{Optimization}}},
  author = {Nocedal, Jorge and Wright, Stephen J.},
  date = {2006},
  series = {Springer {{Series}} in {{Operations Research}} and {{Financial Engineering}}},
  publisher = {{Springer New York}},
  doi = {10.1007/978-0-387-40065-5},
  url = {http://link.springer.com/10.1007/978-0-387-40065-5},
  urldate = {2023-01-10},
  isbn = {978-0-387-30303-1},
  langid = {english},
  keywords = {algorithms,Calculus of Variations,linear optimization,nonlinear optimization,operations research,optimization,quadratic programming,Quasi-Newton method},
  file = {/home/pedro/Documents/doc/zotero/2006_Numerical Optimization.pdf}
}

@article{osman1996metaheuristics,
  title = {Metaheuristics: {{A}} Bibliography},
  shorttitle = {Metaheuristics},
  author = {Osman, Ibrahim H. and Laporte, Gilbert},
  date = {1996-10-01},
  journaltitle = {Annals of Operations Research},
  shortjournal = {Ann Oper Res},
  volume = {63},
  number = {5},
  pages = {511--623},
  issn = {1572-9338},
  doi = {10.1007/BF02125421},
  url = {https://doi.org/10.1007/BF02125421},
  urldate = {2023-01-14},
  abstract = {Metaheuristics are the most exciting development in approximate optimization techniques of the last two decades. They have had widespread successes in attacking a variety of difficult combinatorial optimization problems that arise in many practical areas. This bibliography provides a classification of a comprehensive list of 1380 references on the theory and application of metaheuristics. Metaheuristics include but are not limited to constraint logic programming; greedy random adaptive search procedures; natural evolutionary computation; neural networks; non-monotonic search strategies; space-search methods; simulated annealing; tabu search; threshold algorithms and their hybrids. References are presented in alphabetical order under a number of subheadings.},
  langid = {english},
  keywords = {Artificial intelligence,bibliography,combinatorial optimization,constraint logic programming,evolutionary computation,genetic algorithms,greedy random adaptive search procedure,heuristics,hybrids,local search,metaheuristics,neural networks,non-monotonic search strategies,problem-space method,simulated annealing,tabu search,threshold algorithms},
  file = {/home/pedro/Documents/doc/zotero/Osman_Laporte_1996_Metaheuristics.pdf}
}

@thesis{outeiro2021application,
  type = {Msc Thesis},
  title = {An {{Application Programming Interface}} for {{Constructive Search}}},
  author = {do Outeiro, Samuel Barroca},
  date = {2021-11-09},
  institution = {{University of Coimbra, Portugal}},
  url = {https://estudogeral.sib.uc.pt/handle/10316/98261},
  urldate = {2023-01-10},
  abstract = {A utilização prática de otimização está intimamente relacionada com a disponibilidade de ferramentas de software para a suportar. As abordagens atuais para otimização combinatória caem em duas categorias: modelos de caixa branca (ou transparente) tais como Programação Linear Inteira (ILP) e Programação por Restrições (CP), e modelos de problemas e algoritmos (tipicamente heurísticos) de caixa cinzenta/preta que são diretamente implementados em software. Estes últimos poderão ser mais flexíveis e fáceis de integrar em fluxos de trabalho existentes. Contudo, a falta de convenções para a modelação/implementação de problemas de otimização em software dificultam a sua adoção na prática. De facto, distintos frameworks de software de otimização tipicamente obrigam a que os problemas estejam implementados nessa framework. Para além disso, a maioria das frameworks focam-se principalmente em algoritmos de procura local ao invés de procura construtiva. Assim, surge uma oportunidade para o desenvolvimento de uma Interface de Programação de Aplicações (API) para problemas e algoritmos de procura construtiva.Esta API separa o (modelo do) problema do algoritmo que o resolve através da especificação de várias operações elementares e abstratas que os problemas precisam de implementar e que os algoritmos podem usar independentemente do problema. Tanto algoritmos exatos, como (meta)heurísticos são suportados, dos quais se destacam o Branch \& Bound, o Beam Search, o GRASP, os algoritmos de Ant Colony Optimization, entre outros.As consequências da abstração proposta para o desenvolvimento de novos algoritmos de procura construtiva são também discutidos neste trabalho. Em particular, é conduzido um estudo sobre o efeito dos modelos de problemas no desempenho de algoritmos. Este estudo sugere que um melhor modelo poderá potencialmente beneficiar todos os algoritmos que o usam.},
  langid = {english},
  annotation = {Accepted: 2022-02-02T23:10:29Z},
  file = {/home/pedro/Documents/doc/zotero/Outeiro_2021_An Application Programming Interface for Constructive Search.pdf}
}

@book{papadimitriou1998combinatorial,
  title = {Combinatorial {{Optimization}}: {{Algorithms}} and {{Complexity}}},
  shorttitle = {Combinatorial {{Optimization}}},
  author = {Papadimitriou, Christos H. and Steiglitz, Kenneth},
  date = {1998-01-01},
  publisher = {{Courier Corporation}},
  abstract = {This clearly written, mathematically rigorous text includes a novel algorithmic exposition of the simplex method and also discusses the Soviet ellipsoid algorithm for linear programming; efficient algorithms for network flow, matching, spanning trees, and matroids; the theory of NP-complete problems; approximation algorithms, local search heuristics for NP-complete problems, more. All chapters are supplemented by thought-provoking problems. A useful work for graduate-level students with backgrounds in computer science, operations research, and electrical engineering. "Mathematicians wishing a self-contained introduction need look no further." — American Mathematical Monthly.},
  isbn = {978-0-486-40258-1},
  langid = {english},
  pagetotal = {530},
  keywords = {Mathematics / Combinatorics},
  file = {/home/pedro/Documents/doc/zotero/Papadimitriou_Steiglitz_1998_Combinatorial Optimization.pdf}
}

@incollection{resende2010greedya,
  title = {Greedy {{Randomized Adaptive Search Procedures}}: {{Advances}}, {{Hybridizations}}, and {{Applications}}},
  shorttitle = {Greedy {{Randomized Adaptive Search Procedures}}},
  booktitle = {Handbook of {{Metaheuristics}}},
  author = {Resende, Mauricio G.C. and Ribeiro, Celso C.},
  editor = {Gendreau, Michel and Potvin, Jean-Yves},
  date = {2010},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  pages = {283--319},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4419-1665-5_10},
  url = {https://doi.org/10.1007/978-1-4419-1665-5_10},
  urldate = {2023-01-15},
  abstract = {GRASP is a multi-start metaheuristic for combinatorial optimization problems, in which each iteration consists basically of two phases: construction and local search. The construction phase builds a feasible solution, whose neighborhood is investigated until a local minimum is found during the local search phase. The best overall solution is kept as the result. In this chapter, we first describe the basic components of GRASP. Successful implementation techniques are discussed and illustrated by numerical results obtained for different applications. Enhanced or alternative solution construction mechanisms and techniques to speed up the search are also described: alternative randomized greedy construction schemes, Reactive GRASP, cost perturbations, bias functions, memory and learning, local search on partially constructed solutions, hashing, and filtering. We also discuss implementation strategies of memory-based intensification and post-optimization techniques using path-relinking. Hybridizations with other metaheuristics, parallelization strategies, and applications are also reviewed.},
  isbn = {978-1-4419-1665-5},
  langid = {english},
  keywords = {Bias Function,Construction Phase,Iterate Local Search,Local Search,Tabu Search},
  file = {/home/pedro/Documents/doc/zotero/Resende_Ribeiro_2010_Greedy Randomized Adaptive Search Procedures.pdf}
}

@article{rinnooykan1993class,
  title = {A Class of Generalized Greedy Algorithms for the Multi-Knapsack Problem},
  author = {Rinnooy Kan, A. H. G. and Stougie, L. and Vercellis, C.},
  date = {1993-04-27},
  journaltitle = {Discrete Applied Mathematics},
  shortjournal = {Discrete Applied Mathematics},
  volume = {42},
  number = {2},
  pages = {279--290},
  issn = {0166-218X},
  doi = {10.1016/0166-218X(93)90051-O},
  url = {https://www.sciencedirect.com/science/article/pii/0166218X9390051O},
  urldate = {2023-01-12},
  abstract = {A class of generalized greedy algorithms is proposed for the solution of the [lcub]0,1[rcub] multi-knapsack problem. Items are selected according to decreasing ratios of their profit and a weighted sum of their requirement coefficients. The solution obtained depends on the choice of the weights. A geometrical representation of the method is given and the relation to the dual of the linear programming relaxation of multi-knapsack is exploited. We investigate the complexity of computing a set of weights that gives the maximum greedy solution value. Finally, the heuristics are subjected to both a worst-case and a probabilistic performance analysis.},
  langid = {english},
  keywords = {computational complexity,greedy heuristic,linear programming relaxation,Multi-knapsack problem,probabilistic analysis,worst-case analysis},
  file = {/home/pedro/Documents/doc/zotero/Rinnooy Kan et al_1993_A class of generalized greedy algorithms for the multi-knapsack problem.pdf;/home/pedro/Zotero/storage/IDMBLAMX/0166218X9390051O.html}
}

@thesis{vieira2009uma,
  type = {Doctoral Thesis},
  title = {Uma plataforma para a avaliação experimental de meta-heurísticas},
  author = {Vieira, Ana},
  date = {2009},
  institution = {{University of Algarve, Portugal}},
  url = {https://sapientia.ualg.pt/handle/10400.1/518},
  urldate = {2023-01-10},
  abstract = {Tese de dout., Engenharia Electrónica, Faculdade de Ciências e Tecnologia, Universidade do Algarve, 2009},
  langid = {portuguese},
  annotation = {Accepted: 2011-09-07T16:04:54Z},
  file = {/home/pedro/Documents/doc/zotero/Vieira_2009_Uma plataforma para a avaliação experimental de meta-heurísticas.pdf;/home/pedro/Zotero/storage/Q2ZTZGJP/518.html}
}

@book{williamson2011design,
  title = {The {{Design}} of {{Approximation Algorithms}}},
  author = {Williamson, David P. and Shmoys, David B.},
  date = {2011-04-26},
  edition = {1},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511921735},
  url = {https://www.cambridge.org/core/product/identifier/9780511921735/type/book},
  urldate = {2023-01-13},
  abstract = {Discrete optimization problems are everywhere, from traditional operations research planning (scheduling, facility location and network design); to computer science databases; to advertising issues in viral marketing. Yet most such problems are NP-hard; unless P = NP, there are no efficient algorithms to find optimal solutions. This book shows how to design approximation algorithms: efficient algorithms that find provably near-optimal solutions. The book is organized around central algorithmic techniques for designing approximation algorithms, including greedy and local search algorithms, dynamic programming, linear and semidefinite programming, and randomization. Each chapter in the first section is devoted to a single algorithmic technique applied to several different problems, with more sophisticated treatment in the second section. The book also covers methods for proving that optimization problems are hard to approximate. Designed as a textbook for graduate-level algorithm courses, it will also serve as a reference for researchers interested in the heuristic solution of discrete optimization problems.},
  isbn = {978-0-511-92173-5},
  langid = {english},
  file = {/home/pedro/Zotero/storage/4JX9SQJH/Williamson and Shmoys - 2011 - The Design of Approximation Algorithms.pdf}
}

@book{witelski2015methods,
  title = {Methods of {{Mathematical Modelling}}},
  author = {Witelski, Thomas and Bowen, Mark},
  date = {2015},
  series = {Springer {{Undergraduate Mathematics Series}}},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-23042-9},
  url = {http://link.springer.com/10.1007/978-3-319-23042-9},
  urldate = {2023-01-15},
  isbn = {978-3-319-23041-2},
  langid = {english},
  file = {/home/pedro/Zotero/storage/3HS7QHKI/Witelski and Bowen - 2015 - Methods of Mathematical Modelling.pdf}
}

@incollection{yu2010combinatorial,
  title = {Combinatorial {{Optimization}}},
  booktitle = {Introduction to {{Evolutionary Algorithms}}},
  editor = {Yu, Xinjie and Gen, Mitsuo},
  date = {2010},
  series = {Decision {{Engineering}}},
  pages = {263--324},
  publisher = {{Springer}},
  location = {{London}},
  doi = {10.1007/978-1-84996-129-5_7},
  url = {https://doi.org/10.1007/978-1-84996-129-5_7},
  urldate = {2023-01-12},
  abstract = {Previous chapters discuss parameter optimization, i.e., we need to find the optimal values of variables so that the objective function has the maximum/minimum value. Many real-world problems are not like this. We often need to select some elements from a set or arrange the sequence of some events with constraints so that the objective function has the maximum/minimum value. These problems belong to combinatorial optimization. We will introduce three examples, explain their respective properties, illustrate how EAs solve them, and summarize design-effective algorithms for them.},
  isbn = {978-1-84996-129-5},
  langid = {english},
  keywords = {Active Schedule,Hamiltonian Cycle,Knapsack Problem,Travel Salesman Problem},
  file = {/home/pedro/Documents/doc/zotero/2010_Combinatorial Optimization.pdf}
}
