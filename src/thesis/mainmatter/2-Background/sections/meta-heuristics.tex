In the literature, a multitude of meta-heuristic algorithms have emerged over
the years, exploring various ideas to guide the search
process~\cite{osman1996metaheuristics}. These encompass strategies that narrow
the search space to promising regions, enhance solutions in a greedy manner, or
utilize randomized and probabilistic techniques, some of which draw inspiration
from natural phenomena like collective behavior, natural selection, and physical
processes of materials.

However, the majority of state-of-the-art meta-heuristic algorithms can be
described by a couple of distinctive traits~\cite{blum2003metaheuristics} such as:

\begin{description}
  \item[\textbf{Search Strategy.}] This refers to the method used to construct a
    solution. It can be one of three main types: constructive (building step by
    step), local (making small improvements), or a composite approach that
    combines both strategies.

  \item[\textbf{Memoization.}] This concept involves maintaining a record or
    archive of previously explored solutions.~This record helps in identifying
    solutions that may be revisited or disregarded in subsequent stages of the
    optimization process.

  \item[\textbf{Population vs. Trajectory.}] This pertains to the number of
    solutions being evolved during the construction phase.~In~\emph{population
      methods}, multiple solutions are worked with at each iteration, while in
    ~\emph{trajectory methods}, only a single solution is dealt with at a time.
\end{description}

In this section, we will offer a brief overview of select state-of-the-art
\acrshort{meta-heuristic} algorithms, which encapsulate all the above properties
and will be utilized and implemented in the context of this work.

\subsection{Beam Search}
\label{subsec:beam-search}

\acrfull{beam-search}~\cite{ow1988filtered,outeiro2021application}

\begin{algorithm}
  \label{algorithm:beam-search}
  \caption{\acrlong{beam-search}}
  \input{mainmatter/2-Background/algorithms/bs.tex}
\end{algorithm}

\subsection{Iterated Greedy}
\label{subsec:iterated-greedy}

\acrfull{iterated-greedy}~\cite{stutzle2018iterated,outeiro2021application}

\begin{algorithm}
  \label{algorithm:iterated-greedy}
  \caption{\acrlong{iterated-greedy}}
  \input{mainmatter/2-Background/algorithms/ig.tex}
\end{algorithm}

\subsection{Greedy Randomized Adaptive Search Procedure}
\label{subsec:grasp}

\acrfull{grasp}~\cite{resende2010greedya,outeiro2021application,blum2003metaheuristics}

% Greedy Randomized Adaptive Search Procedures
% (GRASP) are
% simple, single-state, stochastic meta-heuristics that iteratively build solutions by
% combining a greedy construction phase with a local search phase. The
% construction phase involves the selection of components from the ground set
% $\mathcal{G}$ based on their contribution to the objective function, using a
% greedy criterion, and subsequently incorporating them into a partial solution
% $s^{p}$. However, the constructed solution may not be feasible, requiring a
% repair process to improve its quality. The local search phase is then applied to
% the partial solution $s^{p}$ obtained during the construction phase, with the
% goal of further completing and improving the solution. The pseudo-code provided
% in Algorithm~\ref{algorithm:grasp} illustrates the functioning of a basic
% implementation of the GRASP algorithm.

\begin{algorithm}
  \label{algorithm:grasp}
  \caption{\acrlong{grasp}}
  \input{mainmatter/2-Background/algorithms/grasp.tex}
\end{algorithm}

\subsection{Ant Colony Optimization}
\label{subsec:aco}

\acrfull{aco}~\cite{dorigo2010anta,outeiro2021application,luke2013essentialsa,blum2003metaheuristics}

% Ant Colony Optimization (ACO is a population-based, stochastic,
% constructive meta-heuristic that is inspired by the foraging behavior of ants.
% 
% The algorithm simulates the movement of ``ants'' through the search space, where
% each ant constructs a solution by making a sequence of probabilistic choices
% based on the ``pheromone'' trail left by previous ants. Notably, the pheromones,
% associated with the components $c_{i}$ of the ground set $\mathcal{G}$, weigh
% the relevance of the integration of a specific component in a solution during
% the construction process.
% 
% One of the key features of ACO is the incorporation of a learning component
% through the use of a pheromone update rule that adapts the pheromone trail based
% on the quality of the solutions constructed by the ants, with the aim of guiding
% the ants towards better solutions over subsequent iterations. As such, the
% algorithm requires the tuning of several parameters such as the pheromone
% evaporation rate, the choice of the pheromone update rule, and the
% initialization of the pheromone trail.
% 
% In summary, the ACO meta-heuristic can be described as a process that comprises
% of a solution construction phase, in which solutions (referred to as ``ants'')
% are constructed, followed by an optional phase of exploiting these solutions
% through local search, and culminating in a pheromone update phase. This process
% is then repeated for multiple iterations, as can be observed in the pseudo-code
% provided in Algorithm ~\ref{algorithm:aco}.
% 
\begin{algorithm}
  \label{algorithm:aco}
  \caption{\acrlong{aco}}
  \input{mainmatter/2-Background/algorithms/aco.tex}
\end{algorithm}

\subsection{Hill-Climbing}
\label{subsec:hill-climbing}

\acrfull{hill-climbing}~\cite{luke2013essentialsa,vieira2009uma} is a simple
stochastic, memory-less,~\acrshort{local-search} trajectory algorithm that works
by iteratively attempting to improve a starting solution through a sequence of
incremental changes,~\ie{}, by selecting the solution in the neighborhood that
yields the best increment with respect to the objective value. This process
terminates when the best solution possible is found or another stopping
criteria is met. Despite the simplicity of this method it is worth noting that,
due to the inherent greedy choice of the best at each step this approach is
susceptible to getting trapped in local optima. For illustration purposes the
pseudocode of simple version of an~\acrshort{hill-climbing} method is shown
in~\Cref{algorithm:hill-climbing}.

\begin{algorithm}
  \input{mainmatter/2-Background/algorithms/hc.tex}
  \caption{\acrlong{hill-climbing}}
  \label{algorithm:hill-climbing}
\end{algorithm}

It's worth noting that the presented algorithm's effectiveness is rooted in the
efficiency of a random process, which strives to improve solution quality
through a sequence of perturbation attempts (\texttt{Perturb} function).
Nevertheless, there exist two noteworthy variations that more thoroughly explore
the solution's neighborhood and take steps in the direction of the most
substantial improvement. These are commonly known as~\acrfull{first-improvement}
and~\acrfull{best-improvement}. The latter is also known in the literature as
\textit{steepest ascent}~\acrshort{hill-climbing}~\cite{luke2013essentialsa}.

In a~\acrshort{first-improvement} approach, the first neighboring solution that
improves the current solution's quality is retained. Conversely, in a
\acrshort{best-improvement} scenario, the entire neighborhood of the current
solution is examined, and the best neighboring solution is selected for the
subsequent iteration.

\subsection{Iterated Local Search}
\label{subsec:iterated-local-search}

\acrfull{iterated-local-search}~\cite{lourenco2010iterateda,luke2013essentialsa,blum2003metaheuristics}

% The  is a single-state, stochastic, local search meta-heuristic
% that builds upon the ideas of Hill Climbing (HC) by incorporating repeated local
% searches starting from different solutions, allowing for exploration of the
% search space. In its simplest form, ILS can be implemented according to the
% pseudo-code shown in Algorithm~\ref{algorithm:iterated-local-search}. Variants
% of the ILS algorithm also exist, such as the memory-based, which store previously
% visited starting solutions to avoid re-exploration of the same regions of the
% search space.
% 
\begin{algorithm}
  \label{algorithm:iterated-local-search}
  \caption{\acrlong{iterated-local-search}}
  \input{mainmatter/2-Background/algorithms/ils.tex}
\end{algorithm}

\subsection{Simulated Annealing}
\label{subsec:simulated-annealing}

\acrfull{simulated-annealing}~\cite{kirkpatrick1983optimization,nikolaev2010simulateda,eglese1990simulated}

%is a single-state, stochastic, local
% search meta-heuristic that is inspired by the process of annealing in
% metallurgy.  The algorithm works by iteratively applying small perturbations to
% a candidate solution with the aim of improving it, and accepting new solutions
% based on their quality and a probability function that simulates the cooling
% process of a metal. The probability function is controlled by a temperature
% parameter, which gradually decreases over time, thus reducing the acceptance
% probability of worse solutions. This allows the algorithm to initially explore a
% wider range of solutions and escape local optima, ultimately improving the
% exploration of the search space. The details of the process can be found in the
% pseudo-code provided in Algorithm~\ref{algorithm:simmulated-annealing}.
% 
\begin{algorithm}
  \label{algorithm:simmulated-annealing}
  \caption{\acrlong{simulated-annealing}}
  \input{mainmatter/2-Background/algorithms/sa.tex}
\end{algorithm}

\subsection{Tabu Search}
\label{subsec:tabu-search}

\acrfull{tabu-search}~\cite{glover1999tabu,gendreau2010tabua,luke2013essentialsa}

% Tabu Search (TS)~\cite{} is a single-state, stochastic, local search meta-heuristic
% that incorporates the use of memory to guide the search process. The algorithm
% iteratively explores the solution space by performing neighborhood searches for
% the best solutions, while maintaining a tabu list $\mathcal{T}$ of recently
% visited solutions that are temporarily forbidden from being revisited. The main
% idea behind this approach is that by avoiding previously visited solutions, the
% algorithm can escape local optima and explore new regions of the search space.
% The size and duration of the tabu list, as well as the rules for adding and
% removing solutions from the list, are user-specified parameters that need to be
% fine-tuned for each problem. The pseudo-code in
% Algorithm~\ref{algorithm:tabu-search} illustrates a simple version of this
% meta-heuristic.

\begin{algorithm}
  \label{algorithm:tabu-search}
  \caption{\acrlong{tabu-search}}
  \input{mainmatter/2-Background/algorithms/ts.tex}
\end{algorithm}

\subsection{Outline}
\label{subsec:Outline}